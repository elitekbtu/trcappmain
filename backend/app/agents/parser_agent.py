#!/usr/bin/env python3
"""
Lamoda Parser Agent

–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ —Å Lamoda.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –ø–∞—Ä—Å–∏–Ω–≥–∞ –∏ –¥–æ–º–µ–Ω—ã .ru, .kz, .by
"""

import asyncio
import json
import re
import random
import time
from dataclasses import dataclass
from typing import List, Optional, Dict, Any
from urllib.parse import urljoin, urlparse, parse_qs, quote

import httpx
from bs4 import BeautifulSoup

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–æ–º–µ–Ω–æ–≤
LAMODA_DOMAINS = {
    "ru": {"host": "https://www.lamoda.ru", "currency": "‚ÇΩ"},
    "kz": {"host": "https://www.lamoda.kz", "currency": "‚Ç∏"},
    "by": {"host": "https://www.lamoda.by", "currency": "—Ä."}
}

@dataclass
class Product:
    sku: str
    name: str
    brand: str
    price: float
    old_price: Optional[float]
    url: str
    image_url: str  # –û—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    image_urls: List[str]  # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–∞


class LamodaParser:
    def __init__(self, domain: str = "ru"):
        if domain not in LAMODA_DOMAINS:
            raise ValueError(f"Unsupported domain: {domain}")
        
        self.domain = domain
        self.base_url = LAMODA_DOMAINS[domain]["host"]
        self.currency = LAMODA_DOMAINS[domain]["currency"]
        
        # –ë–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Language': 'ru-RU,ru;q=0.9,en;q=0.8,kk;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0',
            'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"',
        }
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
        self.session = None

    async def _get_session(self):
        """–ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å HTTP —Å–µ—Å—Å–∏—é"""
        if self.session is None:
            timeout = httpx.Timeout(30.0, connect=10.0)
            self.session = httpx.AsyncClient(
                headers=self.headers,
                timeout=timeout,
                follow_redirects=True,
                limits=httpx.Limits(max_keepalive_connections=5, max_connections=10)
            )
        return self.session

    async def _make_request(self, url: str, **kwargs) -> Optional[httpx.Response]:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å HTTP –∑–∞–ø—Ä–æ—Å —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        session = await self._get_session()
        
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è
            await asyncio.sleep(random.uniform(0.5, 1.5))
            
            response = await session.get(url, **kwargs)
            
            if response.status_code == 429:  # Too Many Requests
                print(f"Rate limited, waiting...")
                await asyncio.sleep(random.uniform(5, 10))
                return await self._make_request(url, **kwargs)
            
            if response.status_code in [200, 301, 302]:
                return response
            else:
                print(f"HTTP {response.status_code} for {url}")
                return None
            
        except Exception as e:
            print(f"Request failed for {url}: {e}")
            return None

    def _extract_price(self, text: str) -> Optional[float]:
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å —É—á–µ—Ç–æ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Lamoda"""
        if not text:
            return None
        
        # –û—á–∏—â–∞–µ–º –æ—Ç HTML —Ç–µ–≥–æ–≤ –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        text = re.sub(r'<[^>]+>', '', text)
        text = text.strip()
        
        # –£–±–∏—Ä–∞–µ–º –≤–∞–ª—é—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        clean_text = text.replace('‚Ç∏', '').replace('‚ÇΩ', '').replace('—Ä.', '').strip()
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Ü–µ–Ω —Å –ø—Ä–æ–±–µ–ª–∞–º–∏ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç Lamoda)
        # –ù–∞–ø—Ä–∏–º–µ—Ä: "15 990", "2 350", "125 000"
        price_pattern = r'\b(\d{1,3}(?:\s+\d{3})*)\b'
        
        matches = re.findall(price_pattern, clean_text)
        
        if matches:
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é —Ü–µ–Ω—É
            price_str = matches[0].replace(' ', '')
            try:
                price = float(price_str)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã (–æ—Ç 100 –¥–æ 10 –º–ª–Ω —Ç–µ–Ω–≥–µ/—Ä—É–±–ª–µ–π)
                if 100 <= price <= 10000000:
                    return price
            except ValueError:
                pass
        
        # Fallback: –∏—â–µ–º –ª—é–±—ã–µ —á–∏—Å–ª–∞ –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤
        fallback_pattern = r'\b(\d{3,7})\b'
        fallback_matches = re.findall(fallback_pattern, clean_text)
        
        if fallback_matches:
            for match in fallback_matches:
                try:
                    price = float(match)
                    if 100 <= price <= 10000000:
                        return price
                except ValueError:
                    continue
        
        return None

    def _extract_prices_from_element(self, element) -> Optional[Dict[str, Optional[float]]]:
        """–¢–æ—á–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞ –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Lamoda"""
        try:
            price_info = {
                'current_price': None,
                'old_price': None
            }
            
            # –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Lamoda
            price_selectors = {
                'new_price': [
                    '.x-product-card-description__price-new',
                    'span[class*="price-new"]', 
                    'span[class*="price_new"]',
                    '.product-card__price_new'
                ],
                'old_price': [
                    '.x-product-card-description__price-old',
                    '.x-product-card-description__price-second-old',
                    'span[class*="price-old"]',
                    'span[class*="price_old"]',
                    '.product-card__price_old'
                ],
                'single_price': [
                    '.x-product-card-description__price-single',
                    'span[class*="price-single"]',
                    'span[class*="price_single"]',
                    '.product-card__price:not([class*="old"]):not([class*="new"])'
                ]
            }
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–≤—É—é (–∞–∫—Ç—É–∞–ª—å–Ω—É—é) —Ü–µ–Ω—É
            for selector in price_selectors['new_price']:
                price_elem = element.select_one(selector)
                if price_elem:
                    price_text = price_elem.get_text(strip=True)
                    if price_text and ('‚Ç∏' in price_text or '‚ÇΩ' in price_text or '—Ä.' in price_text):
                        price = self._extract_price(price_text)
                        if price:
                            price_info['current_price'] = price
                            break
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ä—É—é —Ü–µ–Ω—É  
            for selector in price_selectors['old_price']:
                old_price_elem = element.select_one(selector)
                if old_price_elem:
                    old_price_text = old_price_elem.get_text(strip=True)
                    if old_price_text and ('‚Ç∏' in old_price_text or '‚ÇΩ' in old_price_text or '—Ä.' in old_price_text):
                        old_price = self._extract_price(old_price_text)
                        if old_price:
                            price_info['old_price'] = old_price
                            break
            
            # –ï—Å–ª–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π —Ü–µ–Ω—ã –Ω–µ—Ç, –∏—â–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—É—é —Ü–µ–Ω—É
            if not price_info['current_price']:
                for selector in price_selectors['single_price']:
                    price_elem = element.select_one(selector)
                    if price_elem:
                        price_text = price_elem.get_text(strip=True)
                        if price_text and ('‚Ç∏' in price_text or '‚ÇΩ' in price_text or '—Ä.' in price_text):
                            price = self._extract_price(price_text)
                            if price:
                                price_info['current_price'] = price
                                break
            
            # Fallback: –∏—â–µ–º –ª—é–±—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ü–µ–Ω–∞–º–∏ –≤ —Ç–µ–∫—Å—Ç–µ
            if not price_info['current_price']:
                element_text = element.get_text()
                all_price_matches = re.findall(r'(\d{1,3}(?:\s+\d{3})*)\s*[‚Ç∏‚ÇΩ]', element_text)
                
                if all_price_matches:
                    prices = []
                    for price_str in all_price_matches:
                        try:
                            price = float(price_str.replace(' ', ''))
                            if 100 <= price <= 10000000:
                                prices.append(price)
                        except ValueError:
                            continue
                    
                    if prices:
                        prices.sort()
                        price_info['current_price'] = prices[0]  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞
                        if len(prices) > 1:
                            price_info['old_price'] = prices[-1]  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—á–Ω–æ—Å—Ç—å —Ü–µ–Ω
            if price_info['current_price'] and price_info['old_price']:
                # –°—Ç–∞—Ä–∞—è —Ü–µ–Ω–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –±–æ–ª—å—à–µ –Ω–æ–≤–æ–π
                if price_info['old_price'] <= price_info['current_price']:
                    price_info['old_price'] = None
            
            return price_info if price_info['current_price'] else None
            
        except Exception as e:
            print(f"‚ùå Error extracting prices: {e}")
            return None

    async def _try_real_search(self, query: str, limit: int = 20, page: int = 1) -> List[Product]:
        """–†–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ Lamoda –∏—Å–ø–æ–ª—å–∑—É—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑ –ø—Ä–∏–º–µ—Ä–∞"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π URL —Ñ–æ—Ä–º–∞—Ç –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ
            search_url = f"{self.base_url}/catalogsearch/result/"
            params = {
                'q': query,
                'submit': 'y'
            }
            
            if page > 1:
                params['p'] = page
            
            print(f"Searching: {search_url} with query: {query}")
            
            response = await self._make_request(search_url, params=params)
            if not response:
                print("Failed to get response")
                return []
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            products = self._parse_lamoda_products(soup, limit)
            
            if products:
                print(f"Successfully parsed {len(products)} products")
                return products
            else:
                print("No products found in HTML")
                return []
            
        except Exception as e:
            print(f"Real search failed: {e}")
            return []

    def _parse_lamoda_products(self, soup: BeautifulSoup, limit: int) -> List[Product]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã Lamoda –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        products = []
        
        print("üîç Analyzing page content...")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        print("üîç Trying JSON extraction...")
        json_products = self._extract_json_from_scripts(soup, limit)
        if json_products:
            products.extend(json_products)
            print(f"‚úÖ Found {len(json_products)} products from JSON")
        
        # –ï—Å–ª–∏ JSON –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –ø—Ä–æ–±—É–µ–º HTML –ø–∞—Ä—Å–∏–Ω–≥
        if not products:
            product_blocks = self._find_product_blocks(soup)
            
            if product_blocks:
                print(f"üîç Found {len(product_blocks)} product blocks in HTML")
                
                for i, block in enumerate(product_blocks[:limit]):
                    # –ü—ã—Ç–∞–µ–º—Å—è –ø–∞—Ä—Å–∏—Ç—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–∞—Ä—Ç–æ—á–∫—É
                    product = self._parse_modern_product_card(block, i)
                    if product:
                        products.append(product)
                        print(f"‚úÖ Parsed from HTML: {product.brand} - {product.name} - {product.price}‚Ç∏" + 
                              (f" (was {product.old_price}‚Ç∏)" if product.old_price else ""))
                        
                    if len(products) >= limit:
                        break
        
        # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –Ω–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback regex –ø–∞—Ä—Å–∏–Ω–≥
        if not products:
            print("üîç Fallback to regex text parsing...")
            products = self._parse_from_regex_fallback(soup, limit)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã (–ø–æ SKU, –∞ –Ω–µ –ø–æ –±—Ä–µ–Ω–¥—É –∏ –Ω–∞–∑–≤–∞–Ω–∏—é)
        unique_products: list[Product] = []
        seen_skus: set[str] = set()
        for prod in products:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º SKU –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –∫—Ä–∏—Ç–µ—Ä–∏–π —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
            if prod.sku not in seen_skus:
                seen_skus.add(prod.sku)
                unique_products.append(prod)

        print(f"üìà Final result after deduplication: {len(unique_products)} products (was {len(products)})")
        return unique_products[:limit]

    def _parse_from_regex_fallback(self, soup: BeautifulSoup, limit: int) -> List[Product]:
        """Fallback regex –ø–∞—Ä—Å–∏–Ω–≥ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        products = []
        page_text = soup.get_text()
        
        # –ù–∞ –æ—Å–Ω–æ–≤–µ –≤–µ–±-—Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ Lamoda —Ç–∞–∫–∞—è:
        # "—Ü–µ–Ω–∞‚Ç∏ —Å—Ç–∞—Ä–∞—è_—Ü–µ–Ω–∞‚Ç∏ –∏—Ç–æ–≥–æ–≤–∞—è_—Ü–µ–Ω–∞ ‚Ç∏ –ë—Ä–µ–Ω–¥ –ù–∞–∑–≤–∞–Ω–∏–µ"
        # –ü—Ä–∏–º–µ—Ä: "22 70017 29013 832 ‚Ç∏ PUMA –®–æ—Ä—Ç—ã —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–µ ESS 2 COLOR"
        currency_symbol = self.currency
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        price_patterns = [
            # –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω: –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ü–µ–Ω—ã + –±—Ä–µ–Ω–¥ + –Ω–∞–∑–≤–∞–Ω–∏–µ
            rf'(\d{{1,3}}(?:\s+\d{{3}})*)\s*(\d{{1,3}}(?:\s+\d{{3}})*)\s*(\d{{1,3}}(?:\s+\d{{3}})*)\s*{re.escape(currency_symbol)}\s+([A-Z][A-Za-z\s&\.]+?)\s+([\w\s\-–∞-—è—ë\.,"\'()]+?)(?=\d{{1,3}}(?:\s+\d{{3}})*\s*(?:\d{{1,3}}(?:\s+\d{{3}})*\s*)*{re.escape(currency_symbol)}|$)',
            # –ü–∞—Ç—Ç–µ—Ä–Ω —Å –¥–≤—É–º—è —Ü–µ–Ω–∞–º–∏
            rf'(\d{{1,3}}(?:\s+\d{{3}})*)\s*(\d{{1,3}}(?:\s+\d{{3}})*)\s*{re.escape(currency_symbol)}\s+([A-Z][A-Za-z\s&\.]+?)\s+([\w\s\-–∞-—è—ë\.,"\'()]+?)(?=\d{{1,3}}(?:\s+\d{{3}})*\s*(?:\d{{1,3}}(?:\s+\d{{3}})*\s*)*{re.escape(currency_symbol)}|$)',
            # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω: —Ü–µ–Ω–∞ + –±—Ä–µ–Ω–¥ + –Ω–∞–∑–≤–∞–Ω–∏–µ  
            rf'(\d{{1,3}}(?:\s+\d{{3}})*)\s*{re.escape(currency_symbol)}\s+([A-Z][A-Za-z\s&\.]+?)\s+([\w\s\-–∞-—è—ë\.,"\'()]+?)(?=\d{{1,3}}(?:\s+\d{{3}})*\s*{re.escape(currency_symbol)}|$)',
        ]
        
        print(f"üîç Searching for products with currency: {currency_symbol}")
        
        for pattern_idx, pattern in enumerate(price_patterns):
            matches = re.findall(pattern, page_text, re.MULTILINE | re.IGNORECASE)
            
            if matches:
                print(f"‚úÖ Found {len(matches)} matches with pattern {pattern_idx + 1}")
                
                for i, match in enumerate(matches[:limit]):
                    try:
                        # –†–∞–∑–±–∏—Ä–∞–µ–º match –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–∞
                        if len(match) == 5:  # –ü–∞—Ç—Ç–µ—Ä–Ω —Å 3 —Ü–µ–Ω–∞–º–∏
                            price_str_1, price_str_2, price_str_3, brand_raw, name_raw = match
                            # –ë–µ—Ä–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Ü–µ–Ω—É –∫–∞–∫ –∞–∫—Ç—É–∞–ª—å–Ω—É—é
                            prices = [float(p.replace(' ', '')) for p in [price_str_1, price_str_2, price_str_3]]
                            price = min(prices)
                            old_price = max(prices) if max(prices) > min(prices) else None
                        elif len(match) == 4:  # –ü–∞—Ç—Ç–µ—Ä–Ω —Å 2 —Ü–µ–Ω–∞–º–∏
                            price_str_1, price_str_2, brand_raw, name_raw = match
                            price1 = float(price_str_1.replace(' ', ''))
                            price2 = float(price_str_2.replace(' ', ''))
                            price = min(price1, price2)
                            old_price = max(price1, price2) if price1 != price2 else None
                        else:  # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω —Å 1 —Ü–µ–Ω–æ–π
                            price_str, brand_raw, name_raw = match
                            price = float(price_str.replace(' ', ''))
                            old_price = None
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã
                        if price < 100 or price > 999999:
                            continue
                        
                        # –û—á–∏—â–∞–µ–º –±—Ä–µ–Ω–¥
                        brand = self._clean_brand(brand_raw.strip())
                        if not brand or len(brand) < 2:
                            continue
                        
                        # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                        name = self._clean_name(name_raw.strip())
                        if not name or len(name) < 3:
                            continue
                        
                        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º SKU
                        sku = f"LMD{self.domain.upper()}{len(products) + 1:04d}"
                        
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ–≤–∞—Ä—ã –±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö URL –≤ regex –ø–∞—Ä—Å–∏–Ω–≥–µ
                        continue
                        
                    except Exception as e:
                        print(f"‚ùå Error parsing match {i}: {e}")
                        continue
                
                if products:
                    break  # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ç–æ–≤–∞—Ä—ã, –Ω–µ –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        
        return products

    def _clean_brand(self, brand_raw: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –±—Ä–µ–Ω–¥–∞"""
        # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –±—Ä–µ–Ω–¥—ã
        known_brands = [
            'Nike', 'Adidas', 'Puma', 'Reebok', 'Jordan', 'Converse', 'New Balance', 
            'Vans', 'Under Armour', 'Asics', 'Mizuno', 'Skechers', 'Fila', 'Kappa', 
            'Umbro', 'Diadora', 'Calvin Klein', 'Tommy Hilfiger', 'Lacoste', 'Hugo Boss',
            'Demix', 'Outventure', 'Baon', 'Befree', 'Mango', 'Zara', 'H&M', 'Uniqlo',
            'Euphoria', 'Profit', 'Terranova', 'Pepe Jeans', 'Marco Tozzi', 'Tamaris',
            'Founds', 'Nume', 'Shoiberg', 'T.Taccardi', 'Abricot', 'Pierre Cardin'
        ]
        
        # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        brand_words = brand_raw.split()
        for word in brand_words:
            for known_brand in known_brands:
                if word.lower() == known_brand.lower():
                    return known_brand
        
        # –ò—â–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        for known_brand in known_brands:
            if known_brand.lower() in brand_raw.lower():
                return known_brand
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –∫–∞–∫ –±—Ä–µ–Ω–¥
        first_word = brand_words[0] if brand_words else brand_raw
        return first_word.strip()

    def _clean_name(self, name_raw: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞"""
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ —á–∏—Å–ª–∞ –≤ –∫–æ–Ω—Ü–µ
        name = re.sub(r'\s+\d+\s*$', '', name_raw)  # –£–±–∏—Ä–∞–µ–º —á–∏—Å–ª–∞ –≤ –∫–æ–Ω—Ü–µ
        name = re.sub(r'\s{2,}', ' ', name)  # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        name = name.strip()
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        if len(name) > 80:
            name = name[:80].strip()
        
        return name

    def _find_product_images(self, soup: BeautifulSoup, brand: str, name: str) -> tuple[str, List[str]]:
        """–ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        image_url = ""
        image_urls = []
        
        try:
            brand_lower = brand.lower()
            # –û–≥—Ä–∞–Ω–∏—á–∏–º—Å—è –ø–µ—Ä–≤—ã–º–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Å–ª–æ–≤–∞–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ alt
            name_tokens = [t.lower() for t in name.split()[:3]]

            img_tags = soup.find_all('img')

            candidate_urls: list[str] = []  # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–≤–ø–∞–ª–∏ –ø–æ alt/brand/name
            fallback_urls: list[str] = []   # –í—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–Ω–∞ —Å–ª—É—á–∞–π –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π)

            for img in img_tags:
                src = img.get('src') or img.get('data-src') or img.get('data-original')
                if not src:
                    continue

                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL
                if src.startswith('//'):
                    full_url = 'https:' + src
                elif src.startswith('/'):
                    full_url = urljoin(self.base_url, src)
                else:
                    full_url = src

                if not full_url or 'lmcdn.ru' not in full_url:
                    continue

                if not any(ext in full_url.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp']):
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º alt-—Ç–µ–∫—Å—Ç, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±—Ä–µ–Ω–¥—É/—Ç–æ–≤–∞—Ä—É
                alt_text = (img.get('alt') or '').lower()

                matches_brand = brand_lower in alt_text if brand_lower else False
                matches_name = any(tok in alt_text for tok in name_tokens) if name_tokens else False

                if (matches_brand or matches_name) and full_url not in candidate_urls:
                    candidate_urls.append(full_url)
                elif full_url not in fallback_urls:
                    fallback_urls.append(full_url)

            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ alt/brand/name ‚Äì –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö, –∏–Ω–∞—á–µ fallback
            final_urls = candidate_urls if candidate_urls else fallback_urls

            if final_urls:
                image_url = final_urls[0]
                image_urls.extend(final_urls)
        
        except Exception as e:
            print(f"‚ùå Error finding images: {e}")
        
        return image_url, image_urls

    def _extract_json_from_scripts(self, soup: BeautifulSoup, limit: int) -> List[Product]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ JSON –¥–∞–Ω–Ω—ã—Ö –≤ —Å–∫—Ä–∏–ø—Ç–∞—Ö —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        products = []

        def _find_products_array(text: str) -> Optional[str]:
            """–ù–∞–π—Ç–∏ –∏ –≤–µ—Ä–Ω—É—Ç—å JSON-—Å—Ç—Ä–æ–∫—É –º–∞—Å—Å–∏–≤–∞ products —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π —Å–∫–æ–±–æ–∫"""
            key = '"products"'
            start_key = text.find(key)
            if start_key == -1:
                return None
            # –∏—â–µ–º –ø–µ—Ä–≤—É—é –æ—Ç–∫—Ä—ã–≤–∞—é—â—É—é –∫–≤–∞–¥—Ä–∞—Ç–Ω—É—é —Å–∫–æ–±–∫—É –ø–æ—Å–ª–µ –∫–ª—é—á–∞
            array_start = text.find('[', start_key)
            if array_start == -1:
                return None
            depth = 0
            for idx in range(array_start, len(text)):
                ch = text[idx]
                if ch == '[':
                    depth += 1
                elif ch == ']':
                    depth -= 1
                    if depth == 0:
                        return text[array_start:idx + 1]
            return None
        
        try:
            # –ò—â–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å–æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º–∏ JSON –¥–∞–Ω–Ω—ã–º–∏
            script_tags = soup.find_all('script')
            
            for script in script_tags:
                if not script.string:
                    continue
                    
                script_content = script.string.strip()

                # 1) –ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ products —á–µ—Ä–µ–∑ helper (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ __NUXT__)
                if '"products"' in script_content:
                    products_json_str = _find_products_array(script_content)
                    if products_json_str:
                        try:
                            products_data = json.loads(products_json_str)
                            extracted = self._extract_products_from_lamoda_json(products_data, limit)
                            if extracted:
                                products.extend(extracted)
                                if len(products) >= limit:
                                    return products[:limit]
                        except json.JSONDecodeError as e:
                            print(f"‚ùå JSON decode error (products array): {e}")
                            # fallthrough to regex strategies
                
                # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ JSON —Å —Ç–æ–≤–∞—Ä–∞–º–∏ (—Å—Ç–∞—Ä—ã–µ –º–µ—Ç–æ–¥—ã)
                json_patterns = [
                    # –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è Lamoda
                    r'"products"\s*:\s*(\[[\s\S]*?\])',
                    r'window\.__INITIAL_STATE__\s*=\s*({[\s\S]*?});',
                    r'window\.dataLayer\s*=\s*(\[[\s\S]*?\]);',
                    r'window\.__NEXT_DATA__\s*=\s*({[\s\S]*?});',
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                    r'catalogsearch.*?"products"\s*:\s*(\[[\s\S]*?\])',
                    r'"catalog"\s*:\s*{[\s\S]*?"items"\s*:\s*(\[[\s\S]*?\])',
                ]
                
                for pattern in json_patterns:
                    matches = re.findall(pattern, script_content, re.DOTALL)
                    
                    for match in matches:
                        try:
                            # –ï—Å–ª–∏ —ç—Ç–æ –º–∞—Å—Å–∏–≤ —Ç–æ–≤–∞—Ä–æ–≤
                            if match.strip().startswith('['):
                                products_data = json.loads(match)
                                extracted = self._extract_products_from_lamoda_json(products_data, limit - len(products))
                                if extracted:
                                    products.extend(extracted)
                                    if len(products) >= limit:
                                        return products[:limit]
                                    
                            # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—ä–µ–∫—Ç —Å —Ç–æ–≤–∞—Ä–∞–º–∏
                            else:
                                data = json.loads(match)
                                extracted = self._find_products_in_object(data, limit - len(products))
                                if extracted:
                                    products.extend(extracted)
                                    if len(products) >= limit:
                                        return products[:limit]
                                
                        except json.JSONDecodeError as e:
                            print(f"‚ùå JSON decode error: {e}")
                            continue
                        except Exception as e:
                            print(f"‚ùå Error processing JSON: {e}")
                            continue
                
                if len(products) >= limit:
                    break
        
        except Exception as e:
            print(f"‚ùå Error extracting JSON from scripts: {e}")
        
        return products[:limit]

    def _extract_products_from_lamoda_json(self, products_data: list, limit: int) -> List[Product]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ JSON –º–∞—Å—Å–∏–≤–∞ Lamoda"""
        products = []
        
        for item in products_data[:limit]:
            try:
                product = self._parse_lamoda_product_json(item)
                if product:
                    products.append(product)
            except Exception as e:
                print(f"‚ùå Error parsing product JSON: {e}")
                continue
        
        return products

    def _parse_lamoda_product_json(self, item: dict) -> Optional[Product]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ –∏–∑ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Lamoda"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            sku = item.get('sku', '')
            name = item.get('name', '')
            

            
            # –ë—Ä–µ–Ω–¥ –∏–∑ –æ–±—ä–µ–∫—Ç–∞ brand
            brand = "Unknown"
            if 'brand' in item and isinstance(item['brand'], dict):
                brand = item['brand'].get('name', 'Unknown')
            
            # –¶–µ–Ω–∞
            price = item.get('price_amount', 0)
            if isinstance(price, str):
                try:
                    price = float(price)
                except ValueError:
                    price = 0
            
            # –°—Ç–∞—Ä–∞—è —Ü–µ–Ω–∞
            old_price = item.get('old_price_amount')
            if old_price and isinstance(old_price, str):
                try:
                    old_price = float(old_price)
                except ValueError:
                    old_price = None
            
            # URL —Ç–æ–≤–∞—Ä–∞ - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –ø–æ–ª—è
            url = ""
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä—è–º–æ–µ –ø–æ–ª–µ url
            if 'url' in item and item['url']:
                candidate_url = item['url']
                if candidate_url.startswith('/'):
                    url = f"{self.base_url}{candidate_url}"
                elif candidate_url.startswith('http'):
                    url = candidate_url
            
            # –ï—Å–ª–∏ –Ω–µ—Ç, —Å—Ç—Ä–æ–∏–º URL –∏–∑ SKU + seo_tail (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç Lamoda)
            if not url and sku:
                seo_tail = item.get('seo_tail', '')
                if seo_tail:
                    # –§–æ—Ä–º–∞—Ç: /p/{sku}/{seo_tail}/
                    url = f"{self.base_url}/p/{sku.lower()}/{seo_tail}/"
                else:
                    # –¢–æ–ª—å–∫–æ SKU
                    url = f"{self.base_url}/p/{sku.lower()}/"
            
            # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ seo_tail –µ—Å–ª–∏ –Ω–µ—Ç SKU
            if not url:
                seo_tail = item.get('seo_tail', '')
                if seo_tail and len(seo_tail) > 5:
                    if seo_tail.startswith('/'):
                        url = f"{self.base_url}{seo_tail}"
                    else:
                        url = f"{self.base_url}/p/{seo_tail}/"
            

            
            # –ï—Å–ª–∏ URL –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ–≤–∞—Ä
            if not url:
                print(f"‚ö†Ô∏è Skipping product {sku} - no URL found")
                return None
            
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_url = ""
            image_urls = []
            
            # –û—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            thumbnail = item.get('thumbnail', '')
            if thumbnail:
                if thumbnail.startswith('/'):
                    image_url_raw = f"https://a.lmcdn.ru{thumbnail}"
                else:
                    image_url_raw = thumbnail
                image_url = image_url_raw
                image_urls.append(image_url)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –≥–∞–ª–µ—Ä–µ–∏
            gallery = item.get('gallery', [])
            if isinstance(gallery, list):
                for img_path in gallery:
                    if img_path and img_path.startswith('/'):
                        full_img_url = f"https://a.lmcdn.ru{img_path}"
                        if full_img_url not in image_urls:
                            image_urls.append(full_img_url)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
            if not sku or not name or price <= 0:

                return None
            

            
            return Product(
                sku=sku,
                name=name,
                brand=brand,
                price=price,
                old_price=old_price,
                url=url,
                image_url=image_url,
                image_urls=image_urls
            )
            
        except Exception as e:
            print(f"‚ùå Error parsing Lamoda product JSON: {e}")
            return None

    def _find_products_in_object(self, data: dict, limit: int) -> List[Product]:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –≤ JSON –æ–±—ä–µ–∫—Ç–µ"""
        products = []
        
        def search_recursive(obj, path=""):
            nonlocal products
            
            if len(products) >= limit:
                return
                
            if isinstance(obj, dict):
                # –ò—â–µ–º –∫–ª—é—á–∏ –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–≤–∞—Ä—ã
                product_keys = ['products', 'items', 'catalog', 'results', 'data']
                for key in product_keys:
                    if key in obj and isinstance(obj[key], list):
                        extracted = self._extract_products_from_lamoda_json(obj[key], limit - len(products))
                        products.extend(extracted)
                        if len(products) >= limit:
                            return
                
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥—Ä—É–≥–∏–µ –∫–ª—é—á–∏
                for key, value in obj.items():
                    if key not in product_keys and len(products) < limit:
                        search_recursive(value, f"{path}.{key}")
                        
            elif isinstance(obj, list):
                for i, item in enumerate(obj):
                    if len(products) >= limit:
                        break
                    search_recursive(item, f"{path}[{i}]")
        
        search_recursive(data)
        return products

    def _find_product_blocks(self, soup: BeautifulSoup) -> List:
        """–ù–∞–π—Ç–∏ –±–ª–æ–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤ –≤ HTML"""
        # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã, –Ω–∞—á–∏–Ω–∞—è —Å –Ω–∞–∏–±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö
        selectors = [
            # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ Lamoda
            'a[href*="/p/"]',  # –ü—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã
            'div[class*="product"] a[href]',  # –°—Å—ã–ª–∫–∏ –≤–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤
            'article a[href]',  # –°—Å—ã–ª–∫–∏ –≤ article —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
            '.product-card a[href]',  # –°—Ç–∞—Ä—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
            '.product-card',
            '.product-item',
            '.catalog-item',
            '.item-card',
            # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª–∞—Å—Å–æ–≤
            '[class*="product"]',
            '[class*="item"]',
            '[class*="card"]',
            # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
            'article',
            '.grid-item',
            'li[class*="item"]',
            # Fallback —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
            'div[data-*]',
        ]
        
        for selector in selectors:
            blocks = soup.select(selector)
            if blocks and len(blocks) > 3:  # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ö–æ—Ç—è –±—ã –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä–æ–≤
                print(f"Found product blocks with selector: {selector}")
                return blocks
        
        return []

    def _parse_modern_product_card(self, element, index: int) -> Optional[Product]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–∞ Lamoda"""
        try:
            # –†–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
            product_data = {
                'name': None,
                'brand': None,
                'price': None,
                'old_price': None,
                'url': None,
                'image_url': None,
                'image_urls': []
            }
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
            name_selectors = [
                'h3[class*="title"]',
                'div[class*="title"]',
                'span[class*="title"]',
                '[data-testid*="title"]',
                '[data-testid*="name"]',
                'h1, h2, h3, h4',
                '.product-card__product-name',  # –°—Ç–∞—Ä—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä
            ]
            
            for selector in name_selectors:
                name_elem = element.select_one(selector)
                if name_elem:
                    name_text = name_elem.get_text(strip=True)
                    if name_text and len(name_text) > 3 and name_text != "Product":
                        product_data['name'] = name_text[:100]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                        break
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±—Ä–µ–Ω–¥–∞
            brand_selectors = [
                'span[class*="brand"]',
                'div[class*="brand"]',
                '[data-testid*="brand"]',
                '.product-card__brand-name',  # –°—Ç–∞—Ä—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä
            ]
            
            for selector in brand_selectors:
                brand_elem = element.select_one(selector)
                if brand_elem:
                    brand_text = brand_elem.get_text(strip=True)
                    if brand_text and len(brand_text) > 1 and brand_text != "Unknown":
                        product_data['brand'] = brand_text
                        break
            
            # –ï—Å–ª–∏ –±—Ä–µ–Ω–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
            if not product_data['brand'] and product_data['name']:
                known_brands = ['Nike', 'Adidas', 'Puma', 'Reebok', 'Jordan', 'Converse', 
                               'New Balance', 'Vans', 'Under Armour', 'Asics', 'Mizuno',
                               'Skechers', 'Fila', 'Kappa', 'Umbro', 'Diadora', 'Calvin Klein',
                               'Tommy Hilfiger', 'Lacoste', 'Polo Ralph Lauren', 'Hugo Boss']
                
                name_upper = product_data['name'].upper()
                for brand in known_brands:
                    if brand.upper() in name_upper:
                        product_data['brand'] = brand
                        break
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω—ã —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏
            price_info = self._extract_prices_from_element(element)
            if price_info:
                product_data['price'] = price_info['current_price']
                product_data['old_price'] = price_info['old_price']
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 4: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ URL
            # –£–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–∫–∏
            url_selectors = [
                'a[href*="/p/"]',  # –ü—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã
                'a[href]',  # –õ—é–±—ã–µ —Å—Å—ã–ª–∫–∏
            ]
            
            found_url = None
            for selector in url_selectors:
                link_elem = element.select_one(selector)
                if link_elem and link_elem.get('href'):
                    href = link_elem['href']
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä
                    if href.startswith('/p/') or '/p/' in href:
                        if href.startswith('/'):
                            found_url = urljoin(self.base_url, href)
                        elif href.startswith('http'):
                            found_url = href
                        break
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å—Å—ã–ª–∫—É –≤ —ç–ª–µ–º–µ–Ω—Ç–µ, –∏—â–µ–º –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
            if not found_url:
                parent = element.parent
                for _ in range(3):  # –ò—â–µ–º –Ω–∞ 3 —É—Ä–æ–≤–Ω—è –≤–≤–µ—Ä—Ö
                    if parent and parent.name:
                        parent_link = parent.find('a', href=True)
                        if parent_link:
                            href = parent_link['href']
                            if href.startswith('/p/') or '/p/' in href:
                                if href.startswith('/'):
                                    found_url = urljoin(self.base_url, href)
                                elif href.startswith('http'):
                                    found_url = href
                                break
                        parent = parent.parent
                    else:
                        break
            
            product_data['url'] = found_url
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 5: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            img_selectors = [
                'img[src*="lmcdn"]',
                'img[data-src*="lmcdn"]',
                'img[class*="image"]',
                'img[class*="picture"]',
                'img',
            ]
            
            found_images = set()
            for selector in img_selectors:
                img_elems = element.select(selector)
                for img in img_elems:
                    src = (img.get('src') or img.get('data-src') or 
                          img.get('data-lazy-src') or img.get('data-original'))
                    if src:
                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL
                        if src.startswith('//'):
                            full_url = 'https:' + src
                        elif src.startswith('/'):
                            full_url = urljoin(self.base_url, src)
                        else:
                            full_url = src
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
                        if (full_url and 
                            ('lmcdn.ru' in full_url or 'lamoda' in full_url) and
                            any(ext in full_url.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp']) and
                            full_url not in found_images):
                            found_images.add(full_url)
            
            product_data['image_urls'] = list(found_images)
            if product_data['image_urls']:
                product_data['image_url'] = product_data['image_urls'][0]
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º SKU
            sku = f"LMD{self.domain.upper()}{index + 1:04d}"
            if product_data['url']:
                # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å SKU –∏–∑ URL
                sku_match = re.search(r'/([A-Z0-9]+)/?(?:\?|$)', product_data['url'])
                if sku_match:
                    sku = sku_match.group(1)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
            if not product_data['price'] or not product_data['url']:
                return None
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if not product_data['name']:
                product_data['name'] = "Product"
            if not product_data['brand']:
                product_data['brand'] = "Unknown"
            if not product_data['image_url']:
                product_data['image_url'] = ""
            
            return Product(
                sku=sku,
                name=product_data['name'],
                brand=product_data['brand'],
                price=product_data['price'],
                old_price=product_data['old_price'],
                url=product_data['url'],
                image_url=product_data['image_url'],
                image_urls=product_data['image_urls']
            )
            
        except Exception as e:
            print(f"‚ùå Error in modern parser for element {index}: {e}")
            return None

    def _parse_legacy_product_card(self, card, index: int) -> Optional[Product]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç–∞—Ä–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–∞ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–¥)"""
        return self._parse_product_card(card, index)
    
    def _parse_flexible_product_block(self, block, index: int) -> Optional[Product]:
        """–ì–∏–±–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –ª—é–±–æ–≥–æ –±–ª–æ–∫–∞ —Å —Ç–æ–≤–∞—Ä–æ–º"""
        return self._parse_product_block(block, index)

    def _parse_product_card(self, card, index: int) -> Optional[Product]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–∞ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –±—Ä–µ–Ω–¥
            brand_elem = card.select_one('.product-card__brand-name')
            brand = brand_elem.get_text(strip=True) if brand_elem else "Unknown"
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
            name_elem = card.select_one('.product-card__product-name')
            name = name_elem.get_text(strip=True) if name_elem else "Product"
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—ã —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π
            price_info = self._extract_prices_from_element(card)
            
            if not price_info or not price_info['current_price']:
                print(f"No price found for product {index}")
                return None
            
            price = price_info['current_price']
            old_price = price_info['old_price']
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫—É - —É–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞
            url = ""
            url_selectors = [
                '.product-card__hit-area[href]',
                'a[href*="/p/"]',
                'a[href]'
            ]
            
            for selector in url_selectors:
                link_elem = card.select_one(selector)
                if link_elem and link_elem.get('href'):
                    href = link_elem['href']
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä
                    if href.startswith('/p/') or '/p/' in href or (href.startswith('/') and len(href) > 5):
                        if href.startswith('/'):
                            url = urljoin(self.base_url, href)
                        elif href.startswith('http'):
                            url = href
                        break
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_url = ""
            image_urls = []
            
            # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img_elem = card.select_one('.product-card__pic-img')
            if img_elem:
                src = img_elem.get('src') or img_elem.get('data-src') or img_elem.get('data-lazy-src')
                if src:
                    if src.startswith('//'):
                        image_url = 'https:' + src
                    elif src.startswith('/'):
                        image_url = urljoin(self.base_url, src)
                    else:
                        image_url = src
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Å–ø–∏—Å–æ–∫
                    if image_url:
                        image_urls.append(image_url)
            
            # –ò—â–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            all_imgs = card.select('img')
            for img in all_imgs:
                src = img.get('src') or img.get('data-src') or img.get('data-lazy-src') or img.get('data-original')
                if src:
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL
                    if src.startswith('//'):
                        full_url = 'https:' + src
                    elif src.startswith('/'):
                        full_url = urljoin(self.base_url, src)
                    else:
                        full_url = src
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏ –µ–≥–æ –µ—â–µ –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ
                    if (full_url and 
                        full_url not in image_urls and 
                        ('lmcdn.ru' in full_url or 'lamoda' in full_url) and
                        any(ext in full_url.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp'])):
                        image_urls.append(full_url)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º SKU
            sku = f"LMD{self.domain.upper()}{index + 1:04d}"
            if url:
                # –ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å SKU –∏–∑ URL
                sku_match = re.search(r'/([A-Z0-9]+)/', url)
                if sku_match:
                    sku = sku_match.group(1)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã –∏ –Ω–∞–ª–∏—á–∏–µ URL
            if price > 1000000:
                print(f"Price too high for product {index}: {price}")
                return None
            
            if not url:
                print(f"No valid URL found for product {index}")
                return None
            
            return Product(
                sku=sku,
                name=name.strip(),
                brand=brand.strip(),
                price=price,
                old_price=old_price,
                url=url,
                image_url=image_url,
                image_urls=image_urls
            )
            
        except Exception as e:
            print(f"Error parsing product card {index}: {e}")
            return None

    def _parse_product_block(self, block, index: int) -> Optional[Product]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –±–ª–æ–∫–∞ —Ç–æ–≤–∞—Ä–∞"""
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å –∫–∞–∫ –∫–∞—Ä—Ç–æ—á–∫—É —Ç–æ–≤–∞—Ä–∞
            if hasattr(block, 'select_one'):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∫–∞—Ä—Ç–æ—á–∫–∏
                if (block.select_one('.product-card__brand-name') or 
                    block.select_one('.product-card__product-name') or
                    block.select_one('.product-card__price')):
                    return self._parse_product_card(block, index)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –±–ª–æ–∫–∞
            text = block.get_text(strip=True)
            
            # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Ü–µ–Ω –≤ —Ç–µ–∫—Å—Ç–µ
            price_matches = re.findall(r'(\d+(?:\s+\d+)*)\s*‚Ç∏', text)
            if not price_matches:
                # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ü–µ–Ω—ã –±–µ–∑ –≤–∞–ª—é—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
                price_matches = re.findall(r'(\d+(?:\s+\d+){1,2})', text)
            
            if not price_matches:
                return None
            
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é —Ü–µ–Ω—É (–æ–±—ã—á–Ω–æ —ç—Ç–æ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞)
            price_str = price_matches[0]
            price = float(price_str.replace(' ', ''))
            
            # –ò—â–µ–º —Å—Ç–∞—Ä—É—é —Ü–µ–Ω—É (–µ—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ü–µ–Ω)
            old_price = None
            if len(price_matches) > 1:
                old_price_str = price_matches[1]
                old_price_val = float(old_price_str.replace(' ', ''))
                if old_price_val > price:
                    old_price = old_price_val
            
            # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –±—Ä–µ–Ω–¥–∞ –∏ –Ω–∞–∑–≤–∞–Ω–∏—è
            brand, name = self._extract_brand_and_name(text)
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫—É - —É–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞
            url = ""
            url_selectors = [
                'a[href*="/p/"]',
                'a[href]'
            ]
            
            for selector in url_selectors:
                link = block.select_one(selector)
                if link and link.get('href'):
                    href = link['href']
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä
                    if href.startswith('/p/') or '/p/' in href or (href.startswith('/') and len(href) > 5):
                        if href.startswith('/'):
                            url = urljoin(self.base_url, href)
                        elif href.startswith('http'):
                            url = href
                        break
            
            # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image_url = ""
            image_urls = []
            
            # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ  
            img = block.find('img')
            if img:
                src = img.get('src') or img.get('data-src') or img.get('data-lazy-src') or img.get('data-original')
                if src:
                    if src.startswith('//'):
                        image_url = 'https:' + src
                    elif src.startswith('/'):
                        image_url = urljoin(self.base_url, src)
                    else:
                        image_url = src
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Å–ø–∏—Å–æ–∫
                    if image_url:
                        image_urls.append(image_url)
            
            # –ò—â–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            all_imgs = block.find_all('img')
            for img in all_imgs:
                src = img.get('src') or img.get('data-src') or img.get('data-lazy-src') or img.get('data-original')
                if src:
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL
                    if src.startswith('//'):
                        full_url = 'https:' + src
                    elif src.startswith('/'):
                        full_url = urljoin(self.base_url, src)
                    else:
                        full_url = src
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏ –µ–≥–æ –µ—â–µ –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ
                    if (full_url and 
                        full_url not in image_urls and 
                        ('lmcdn.ru' in full_url or 'lamoda' in full_url) and
                        any(ext in full_url.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp'])):
                        image_urls.append(full_url)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º SKU –∏–∑ —Å—Å—ã–ª–∫–∏ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–¥–µ–∫—Å
            sku = f"LMD{self.domain.upper()}{index + 1:04d}"
            if url:
                # –ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å SKU –∏–∑ URL
                sku_match = re.search(r'/([A-Z0-9]+)/', url)
                if sku_match:
                    sku = sku_match.group(1)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã –∏ –Ω–∞–ª–∏—á–∏–µ URL
            if price > 1000000:
                return None
            
            if not url:
                print(f"No valid URL found for product block {index}")
                return None
            
            return Product(
                sku=sku,
                name=name.strip(),
                brand=brand.strip(),
                price=price,
                old_price=old_price,
                url=url,
                image_url=image_url,
                image_urls=image_urls
            )
            
        except Exception as e:
            print(f"Error parsing product block {index}: {e}")
            return None

    def _extract_brand_and_name(self, text: str) -> tuple[str, str]:
        """–ò–∑–≤–ª–µ—á—å –±—Ä–µ–Ω–¥ –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        text = re.sub(r'[‚Ç∏‚ÇΩ]', '', text)
        text = re.sub(r'\d+(?:\s+\d+)*', '', text)  # –£–±–∏—Ä–∞–µ–º —Ü–µ–Ω—ã
        text = ' '.join(text.split())  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
        
        brand = "Unknown"
        name = "Product"
        
        # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –±—Ä–µ–Ω–¥—ã
        known_brands = [
            'Nike', 'Adidas', 'Puma', 'Reebok', 'Jordan', 'Converse', 
            'New Balance', 'Vans', 'Under Armour', 'Asics', 'Mizuno',
            'Skechers', 'Fila', 'Kappa', 'Umbro', 'Diadora'
        ]
        
        # –ò—â–µ–º –±—Ä–µ–Ω–¥ –≤ —Ç–µ–∫—Å—Ç–µ
        text_lower = text.lower()
        for brand_name in known_brands:
            if brand_name.lower() in text_lower:
                brand = brand_name
                # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –±—Ä–µ–Ω–¥–∞ –∏ –±–µ—Ä–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –Ω–µ–≥–æ –∫–∞–∫ –Ω–∞–∑–≤–∞–Ω–∏–µ
                brand_pos = text_lower.find(brand_name.lower())
                if brand_pos != -1:
                    name_part = text[brand_pos + len(brand_name):].strip()
                    if name_part:
                        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –∫–∞–∫ –Ω–∞–∑–≤–∞–Ω–∏–µ
                        name_words = name_part.split()[:5]
                        if name_words:
                            name = ' '.join(name_words)
                break
        
        # –ï—Å–ª–∏ –±—Ä–µ–Ω–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ –Ω–∞—á–∞–ª–∞ —Ç–µ–∫—Å—Ç–∞
        if brand == "Unknown":
            words = text.split()
            if words:
                # –ü–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –±—Ä–µ–Ω–¥–æ–º
                first_word = words[0]
                if len(first_word) > 2 and first_word.isalpha():
                    brand = first_word
                    if len(words) > 1:
                        name = ' '.join(words[1:6])  # –ë–µ—Ä–µ–º —Å–ª–µ–¥—É—é—â–∏–µ 5 —Å–ª–æ–≤
        
        # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        name = re.sub(r'[^\w\s\-]', '', name).strip()
        if not name or len(name) < 3:
            name = "Product"
        
        return brand, name

    def _parse_from_text(self, text: str, limit: int) -> List[Product]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (fallback –º–µ—Ç–æ–¥)"""
        products = []
        
        # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤
        patterns = [
            # –ü–∞—Ç—Ç–µ—Ä–Ω 1: –¶–µ–Ω–∞ + –≤–∞–ª—é—Ç–∞ + –±—Ä–µ–Ω–¥ + –Ω–∞–∑–≤–∞–Ω–∏–µ
            r'(\d{2,6}(?:\s+\d{3})*)\s*‚Ç∏\s*([A-Za-z]+)\s+([–ê-–Ø–∞-—è\s\w\-]{10,80})',
            # –ü–∞—Ç—Ç–µ—Ä–Ω 2: –ë—Ä–µ–Ω–¥ + –Ω–∞–∑–≤–∞–Ω–∏–µ + —Ü–µ–Ω–∞
            r'([A-Za-z]+)\s+([–ê-–Ø–∞-—è\s\w\-]{10,80})\s+(\d{2,6}(?:\s+\d{3})*)\s*‚Ç∏',
            # –ü–∞—Ç—Ç–µ—Ä–Ω 3: –¢–æ–ª—å–∫–æ —Ü–µ–Ω—ã –æ—Ç 1000 –¥–æ 999999 —Ç–µ–Ω–≥–µ
            r'(\d{4,6})\s*‚Ç∏',
        ]
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã  
        for pattern in patterns[:2]:
            matches = re.findall(pattern, text, re.MULTILINE | re.IGNORECASE)
            
            if matches:
                print(f"Found {len(matches)} matches with pattern")
                for i, match in enumerate(matches[:limit]):
                    try:
                        if len(match) == 3:
                            if pattern.startswith(r'(\d{2,6}'):  # –ü–∞—Ç—Ç–µ—Ä–Ω 1: —Ü–µ–Ω–∞ –ø–µ—Ä–≤–∞—è
                                price_str, brand, name = match
                            else:  # –ü–∞—Ç—Ç–µ—Ä–Ω 2: —Ü–µ–Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è
                                brand, name, price_str = match
                            
                            # –û—á–∏—â–∞–µ–º —Ü–µ–Ω—É –æ—Ç –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å
                            price = float(price_str.replace(' ', ''))
                            if price < 1000 or price > 999999:  # –†–∞–∑—É–º–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã —Ü–µ–Ω –≤ —Ç–µ–Ω–≥–µ
                                continue
                            
                            # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –±—Ä–µ–Ω–¥
                            name = re.sub(r'\s+', ' ', name.strip())
                            name = name[:80]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                            brand = brand.strip()
                            
                            if len(name) < 5 or len(brand) < 2:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
                                continue
                            
                            sku = f"TXT{self.domain.upper()}{i + 1:04d}"
                            
                            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ–≤–∞—Ä—ã –±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö URL
                            continue
                            
                    except Exception as e:
                        print(f"Error parsing text match {i}: {e}")
                        continue
                
                if products:
                    return products
        
        # Fallback: –∏—â–µ–º –ø—Ä–æ—Å—Ç–æ —Ü–µ–Ω—ã –∏ –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ä—è–¥–æ–º —Ç–æ–≤–∞—Ä—ã
        print("Using fallback price-only parsing")
        price_matches = re.findall(patterns[2], text)
        
        if price_matches:
            # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã –æ–∫–æ–ª–æ —Ü–µ–Ω
            segments = re.split(r'\d{4,6}\s*‚Ç∏', text)
            
            for i, price_str in enumerate(price_matches[:limit]):
                try:
                    price = float(price_str)
                    if price < 1000 or price > 999999:
                        continue
                    
                    # –ë–µ—Ä–µ–º —Ç–µ–∫—Å—Ç –¥–æ –∏–ª–∏ –ø–æ—Å–ª–µ —Ü–µ–Ω—ã
                    segment = ""
                    if i < len(segments) - 1:
                        segment = segments[i] + " " + segments[i + 1]
                    elif i < len(segments):
                        segment = segments[i]
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –±—Ä–µ–Ω–¥ –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Å–µ–≥–º–µ–Ω—Ç–∞
                    brand, name = self._extract_brand_and_name(segment)
                    
                    if name == "Product" or brand == "Unknown":
                        name = f"–¢–æ–≤–∞—Ä #{i + 1}"
                        brand = "Generic"
                    
                    sku = f"TXT{self.domain.upper()}{i + 1:04d}"
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ–≤–∞—Ä—ã –±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö URL
                    continue
                    
                except Exception as e:
                    print(f"Error parsing fallback match {i}: {e}")
                    continue
        
        return products

    async def afetch_search(self, query: str, limit: int = 20, page: int = 1) -> List[Product]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤"""
        try:
            print(f"Searching for '{query}' on {self.domain} domain")
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –†–µ–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫
            products = await self._try_real_search(query, limit, page)
            if products:
                print(f"Found {len(products)} products via real search")
                return products
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –î–µ–º–æ —Ä–µ–∂–∏–º –∫–∞–∫ fallback
            print("Real search failed, using demo mode...")
            return self._generate_demo_products(query, limit)
                
        except Exception as e:
            print(f"Search failed: {e}")
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Ç–æ–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ–º–æ –¥–∞–Ω–Ω—ã–µ
            return self._generate_demo_products(query, limit)

    def _generate_demo_products(self, query: str, limit: int) -> List[Product]:
        """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–µ–º–æ —Ç–æ–≤–∞—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è API"""
        demo_products = []
        
        # –ë–∞–∑–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        product_templates = {
            'nike': [
                {'name': 'Nike Air Max 270', 'brand': 'Nike', 'price': 12990, 'old_price': 15990},
                {'name': 'Nike React Infinity Run', 'brand': 'Nike', 'price': 9990, 'old_price': None},
                {'name': 'Nike Air Force 1', 'brand': 'Nike', 'price': 8990, 'old_price': 10990},
            ],
            'adidas': [
                {'name': 'Adidas Ultraboost 22', 'brand': 'Adidas', 'price': 14990, 'old_price': None},
                {'name': 'Adidas Stan Smith', 'brand': 'Adidas', 'price': 6990, 'old_price': 8990},
                {'name': 'Adidas Gazelle', 'brand': 'Adidas', 'price': 7990, 'old_price': None},
            ],
            'puma': [
                {'name': 'Puma Suede Classic', 'brand': 'Puma', 'price': 5990, 'old_price': None},
                {'name': 'Puma RS-X', 'brand': 'Puma', 'price': 8990, 'old_price': 11990},
                {'name': 'Puma Future Rider', 'brand': 'Puma', 'price': 6990, 'old_price': None},
            ]
        }
        
        # –í—ã–±–∏—Ä–∞–µ–º —à–∞–±–ª–æ–Ω—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞
        templates = []
        query_lower = query.lower()
        
        for brand, products in product_templates.items():
            if brand in query_lower:
                templates = products
                break
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –±—Ä–µ–Ω–¥, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–µ —Ç–æ–≤–∞—Ä—ã
        if not templates:
            templates = [
                {'name': f'–¢–æ–≤–∞—Ä –ø–æ –∑–∞–ø—Ä–æ—Å—É "{query}" #{i+1}', 'brand': 'Generic', 'price': 5000 + i * 1000, 'old_price': None}
                for i in range(3)
            ]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä—ã
        for i, template in enumerate(templates[:limit]):
            sku = f"DEMO{query.upper()[:3]}{i+1:03d}"
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–µ–º–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Ç–æ–≤–∞—Ä–∞
            main_image = f"https://a.lmcdn.ru/img600x866/demo/{sku.lower()}_1.jpg"
            demo_images = [
                main_image,
                f"https://a.lmcdn.ru/img600x866/demo/{sku.lower()}_2.jpg",
                f"https://a.lmcdn.ru/img600x866/demo/{sku.lower()}_3.jpg"
            ]
            
            demo_products.append(Product(
                sku=sku,
                name=template['name'],
                brand=template['brand'],
                price=float(template['price']),
                old_price=float(template['old_price']) if template['old_price'] else None,
                url=f"{self.base_url}/p/{sku.lower()}/demo-product-{i+1}/",
                image_url=main_image,
                image_urls=demo_images
            ))
        
        print(f"Generated {len(demo_products)} demo products")
        return demo_products

    def fetch_search(self, query: str, limit: int = 20, page: int = 1) -> List[Product]:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤"""
        return asyncio.run(self.afetch_search(query, limit, page))

    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç—å HTTP —Å–µ—Å—Å–∏—é"""
        if self.session:
            await self.session.aclose()
            self.session = None

    def __del__(self):
        """–î–µ—Å—Ç—Ä—É–∫—Ç–æ—Ä –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏—è —Å–µ—Å—Å–∏–∏"""
        if self.session:
            try:
                asyncio.create_task(self.close())
            except:
                pass


    
    def _generate_sku_from_url(self, url: str, index: int) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç SKU –∏–∑ URL —Ç–æ–≤–∞—Ä–∞"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥ —Ç–æ–≤–∞—Ä–∞ –∏–∑ URL
            # –§–æ—Ä–º–∞—Ç: https://www.lamoda.kz/p/mp002xw0zg9n/clothes-terranova-bryuki/
            # –ù—É–∂–µ–Ω –∞—Ä—Ç–∏–∫—É–ª: mp002xw0zg9n
            path_parts = urlparse(url).path.strip('/').split('/')
            
            # –ò—â–µ–º —á–∞—Å—Ç—å –ø–æ—Å–ª–µ /p/
            if len(path_parts) >= 2 and path_parts[0] == 'p':
                article_code = path_parts[1]
                if len(article_code) >= 8 and article_code.replace('-', '').isalnum():
                    return article_code.upper()
            
            # Fallback - –∏—â–µ–º –ª—é–±—É—é –¥–ª–∏–Ω–Ω—É—é –∞–ª—Ñ–∞–≤–∏—Ç–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—É—é —á–∞—Å—Ç—å
            for part in path_parts:
                if len(part) >= 8 and part.replace('-', '').replace('_', '').isalnum():
                    return part.upper()
            
            # –ü–æ—Å–ª–µ–¥–Ω–∏–π fallback
            return f"LMD{self.domain.upper()}{index + 1:04d}"
            
        except Exception:
            return f"LMD{self.domain.upper()}{index + 1:04d}"


# CLI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Lamoda Product Parser")
    parser.add_argument("query", help="Search query")
    parser.add_argument("--limit", type=int, default=10, help="Max products to fetch")
    parser.add_argument("--domain", choices=list(LAMODA_DOMAINS.keys()), default="ru", help="Lamoda domain")
    parser.add_argument("--page", type=int, default=1, help="Page number")
    
    args = parser.parse_args()
    
    async def main():
        parser_instance = LamodaParser(domain=args.domain)
        try:
            products = await parser_instance.afetch_search(args.query, args.limit, args.page)
            
            if products:
                print(f"\nFound {len(products)} products:")
                for i, product in enumerate(products, 1):
                    print(f"\n{i}. {product.name}")
                    print(f"   Brand: {product.brand}")
                    print(f"   Price: {product.price} {LAMODA_DOMAINS[args.domain]['currency']}")
                    if product.old_price:
                        print(f"   Old Price: {product.old_price} {LAMODA_DOMAINS[args.domain]['currency']}")
                    print(f"   SKU: {product.sku}")
                    print(f"   URL: {product.url}")
                    if product.image_url:
                        print(f"   Image: {product.image_url}")
            else:
                print("No products found")
        finally:
            await parser_instance.close()
    
    asyncio.run(main()) 